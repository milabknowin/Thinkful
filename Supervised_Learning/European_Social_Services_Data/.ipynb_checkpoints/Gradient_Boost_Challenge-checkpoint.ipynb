{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.029187124931805784\n",
      "Percent Type II errors: 0.1373431533006001\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08466257668711656\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# Updated for 1000 iterations & increased tree depth to 3\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Increasing the number of iterations from 500 to 1000, and increasing the tree depth to 3 had the undesired effect of increasing both the type I and type II errors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAEWCAYAAAAEtVmdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0facdb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.031642116748499725\n",
      "Percent Type II errors: 0.13693398799781778\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08220858895705521\n",
      "Percent Type II errors: 0.17914110429447852\n"
     ]
    }
   ],
   "source": [
    "# Using 1000 iterations, increased tree depth to 3 & changed loss function \n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 3,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing the loss function from deviance to exponential decreased the type I and type II errors when compared to the previous model with the same iterations and tree depth, using the deviance loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04841789416257501\n",
      "Percent Type II errors: 0.1778505182760502\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.0638036809815951\n",
      "Percent Type II errors: 0.18773006134969325\n"
     ]
    }
   ],
   "source": [
    "# 500 iterations, tree depth 2, exponential loss function \n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the model with the original parameters of 500 iterations and tree depth of 2 and using the exponential loss function, the type I and type II errors were both higher than the model run with the deviance loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.017048554282596835\n",
      "Percent Type II errors: 0.24549918166939444\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.033128834355828224\n",
      "Percent Type II errors: 0.23558282208588957\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier with 1000 iterations and tree depth of 3\n",
    "\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 3}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "rfc = ensemble.RandomForestClassifier(**params)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "predict_train = rfc.predict(X_train)\n",
    "predict_test = rfc.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.015002727768685215\n",
      "Percent Type II errors: 0.2501363884342608\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.029447852760736196\n",
      "Percent Type II errors: 0.2392638036809816\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier with original parameters\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "rfc2 = ensemble.RandomForestClassifier(**params)\n",
    "rfc2.fit(X_train, y_train)\n",
    "\n",
    "predict_train = rfc2.predict(X_train)\n",
    "predict_test = rfc2.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest yielded the lowest type I errors and highest type II errors of all models compared.  This is true for iterations of 500, tree depth 2, and 1000 iterations, tree depth 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
